{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efeac058-e721-4b72-8727-46b6b1e0b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac1aec2-1855-47d4-ae67-72ef7eab237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 31255\n",
      "val size 3473\n",
      "test size 8682\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "val_df = pd.read_csv(\"../data/val.csv\")\n",
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "print(\"train size\", len(train_df))\n",
    "print(\"val size\", len(val_df))\n",
    "print(\"test size\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6993dc93-a270-4218-a741-b85d5dfa2739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17844</th>\n",
       "      <td>She said that? Wtf?? That's fucked up. I shoul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30841</th>\n",
       "      <td>to 6:30. Does that look fake to you?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16451</th>\n",
       "      <td>Gamers know all too well how it feels to be op...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27141</th>\n",
       "      <td>that tease tonight lowered my hopes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22674</th>\n",
       "      <td>And Tyler Rodriguez solid one-word sentences</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>He made it !!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17949</th>\n",
       "      <td>Speaking of /u/'s \"If your nips aren't leaky.....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25453</th>\n",
       "      <td>Thank you and I try to keep our contact at a m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26164</th>\n",
       "      <td>Me cheering for the Wild this year</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13283</th>\n",
       "      <td>Still pissed we didn’t hire Kyle Shaw. He woul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "17844  She said that? Wtf?? That's fucked up. I shoul...      1\n",
       "30841               to 6:30. Does that look fake to you?      0\n",
       "16451  Gamers know all too well how it feels to be op...      0\n",
       "27141                that tease tonight lowered my hopes      1\n",
       "22674       And Tyler Rodriguez solid one-word sentences      0\n",
       "5426                                      He made it !!!      0\n",
       "17949  Speaking of /u/'s \"If your nips aren't leaky.....      0\n",
       "25453  Thank you and I try to keep our contact at a m...      0\n",
       "26164                 Me cheering for the Wild this year      0\n",
       "13283  Still pissed we didn’t hire Kyle Shaw. He woul...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c1711ff-0aee-42d9-8f38-0dd9b3ba263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_dist = train_df[\"text\"].apply(len)\n",
    "length_dist.hist(log=True, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f992daa9-c9e2-415f-8755-6c19793287ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "label       \n",
       "0      24718\n",
       "1       6537"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb694b2-993e-4c3d-8ad6-36c651d33982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>takes no time to copy/paste a press release</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jazz fan here. I completely feel. Lindsay Mann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ah i was also confused but i think they mean f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you so much. ♥️ that means a lot.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>And I’ll be there!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31250</th>\n",
       "      <td>thank you so much! :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31251</th>\n",
       "      <td>That works too. To each their own.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31252</th>\n",
       "      <td>Friendly fire dude, I wanted the other criminal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31253</th>\n",
       "      <td>Yes, exactly. Fix a date and if he still procr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31254</th>\n",
       "      <td>Ferrets are such good ESA's though! Good for y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24718 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0            takes no time to copy/paste a press release      0\n",
       "2      Jazz fan here. I completely feel. Lindsay Mann...      0\n",
       "3      ah i was also confused but i think they mean f...      0\n",
       "4                Thank you so much. ♥️ that means a lot.      0\n",
       "5                                   And I’ll be there!!!      0\n",
       "...                                                  ...    ...\n",
       "31250                              thank you so much! :)      0\n",
       "31251                 That works too. To each their own.      0\n",
       "31252   Friendly fire dude, I wanted the other criminal       0\n",
       "31253  Yes, exactly. Fix a date and if he still procr...      0\n",
       "31254  Ferrets are such good ESA's though! Good for y...      0\n",
       "\n",
       "[24718 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_neg = train_df[train_df[\"label\"] == 0]\n",
    "train_pos = train_df[train_df[\"label\"] == 1]\n",
    "\n",
    "train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1e658b-d164-4242-b290-cf743a9d7eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Thien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Thien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "en_stopwords = stopwords.words('english')\n",
    "en_stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a3e497-82f1-4fdb-b5e4-ceba58d83a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = set(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73f99df-fbc7-480f-bdc4-881462430d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unigram(texts):\n",
    "    vocab = {}\n",
    "\n",
    "    for x in texts:\n",
    "        words = x.lower().split()\n",
    "        for w in words:\n",
    "            if w not in en_stopwords:\n",
    "                vocab[w] = vocab.get(w,0) + 1\n",
    "\n",
    "    vocab = pd.DataFrame.from_dict(vocab, orient=\"index\", columns=[\"count\"])\n",
    "    vocab.sort_values(\"count\", ascending=False, inplace=True)\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "pos_unigram = count_unigram(train_pos[\"text\"])\n",
    "neg_unigram = count_unigram(train_neg[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77bf1596-ebe6-4840-bfa5-08846e550d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>like</th>\n",
       "      <th>i'm</th>\n",
       "      <th>people</th>\n",
       "      <th>get</th>\n",
       "      <th>sorry</th>\n",
       "      <th>even</th>\n",
       "      <th>really</th>\n",
       "      <th>one</th>\n",
       "      <th>think</th>\n",
       "      <th>would</th>\n",
       "      <th>...</th>\n",
       "      <th>times!</th>\n",
       "      <th>gift</th>\n",
       "      <th>idiots....sheep</th>\n",
       "      <th>thinkers</th>\n",
       "      <th>changes</th>\n",
       "      <th>chemist.</th>\n",
       "      <th>remind</th>\n",
       "      <th>goddamit.</th>\n",
       "      <th>redpiller</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>509</td>\n",
       "      <td>348</td>\n",
       "      <td>321</td>\n",
       "      <td>285</td>\n",
       "      <td>254</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>228</td>\n",
       "      <td>213</td>\n",
       "      <td>212</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 14748 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       like  i'm  people  get  sorry  even  really  one  think  would  ...  \\\n",
       "count   509  348     321  285    254   233     231  228    213    212  ...   \n",
       "\n",
       "       times!  gift  idiots....sheep  thinkers  changes  chemist.  remind  \\\n",
       "count       1     1                1         1        1         1       1   \n",
       "\n",
       "       goddamit.  redpiller  dummy  \n",
       "count          1          1      1  \n",
       "\n",
       "[1 rows x 14748 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_unigram.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c83c5b-5e9e-4264-b48f-5414955cf2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>would</th>\n",
       "      <th>i'm</th>\n",
       "      <th>get</th>\n",
       "      <th>good</th>\n",
       "      <th>one</th>\n",
       "      <th>think</th>\n",
       "      <th>people</th>\n",
       "      <th>really</th>\n",
       "      <th>...</th>\n",
       "      <th>janitors</th>\n",
       "      <th>icu.</th>\n",
       "      <th>minnesota?</th>\n",
       "      <th>reciprocal</th>\n",
       "      <th>rinds?</th>\n",
       "      <th>sullivan.</th>\n",
       "      <th>apparantly</th>\n",
       "      <th>boomhauer(?)(boom-how-er)</th>\n",
       "      <th>stealthy</th>\n",
       "      <th>least,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1784</td>\n",
       "      <td>1258</td>\n",
       "      <td>1008</td>\n",
       "      <td>1007</td>\n",
       "      <td>961</td>\n",
       "      <td>961</td>\n",
       "      <td>907</td>\n",
       "      <td>812</td>\n",
       "      <td>779</td>\n",
       "      <td>770</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       like  love  would   i'm  get  good  one  think  people  really  ...  \\\n",
       "count  1784  1258   1008  1007  961   961  907    812     779     770  ...   \n",
       "\n",
       "       janitors  icu.  minnesota?  reciprocal  rinds?  sullivan.  apparantly  \\\n",
       "count         1     1           1           1       1          1           1   \n",
       "\n",
       "       boomhauer(?)(boom-how-er)  stealthy  least,  \n",
       "count                          1         1       1  \n",
       "\n",
       "[1 rows x 36371 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_unigram.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e5a8bd-e497-444a-bda5-00af7f98652d",
   "metadata": {},
   "source": [
    "Data is clean and does not need any cleaning. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88361145-ea98-4120-ba27-b7a265c6dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc861e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenizer(train_df[\"text\"].to_list(), max_length=512, truncation=True, padding=True)\n",
    "tokenized_val = tokenizer(val_df[\"text\"].to_list(), max_length=512, truncation=True, padding=True)\n",
    "tokenized_test = tokenizer(test_df[\"text\"].to_list(), max_length=512, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ab950f9-6b80-4559-9314-91e9d63ceef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c38b003-650f-41b7-8242-c8442fbe2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenized_text, labels):\n",
    "        self.tokenized_text = tokenized_text\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k,v in self.tokenized_text.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = TextDataset(tokenized_train, train_df[\"label\"].to_list())\n",
    "val_dataset = TextDataset(tokenized_val, val_df[\"label\"].to_list())\n",
    "test_dataset = TextDataset(tokenized_test, test_df[\"label\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d92f8616-eff5-4b4e-875e-debc682434bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  3138,  2053,  2051,  2000,  6100,  1013, 19351,  1037,  2811,\n",
       "          2713,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717be92d-3444-44fb-81df-5014130302e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='173' max='11721' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  173/11721 00:27 < 31:02, 6.20 it/s, Epoch 0.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    logging_dir=\"logs\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai-blitz]",
   "language": "python",
   "name": "conda-env-ai-blitz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
